/*
 * Copyright (c) 2008 Stefan Kempf <sisnkemp@gmail.com>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

%{
#include <sys/types.h>
#include <sys/queue.h>

#include <stdio.h>

#include "comp/comp.h"
#include "comp/ir.h"
#include "comp/cgi.h"

#define EXPRTYPE(n)	(((struct ir_expr *)(n))->ie_type)
#define R8(n)		(IR_ISBYTE(EXPRTYPE(n)))
#define RI8(n)		(IR_ISI8(EXPRTYPE(n)))
#define RU8(n)		(IR_ISU8(EXPRTYPE(n)))
#define R16(n)		(IR_ISWORD(EXPRTYPE(n)))
#define RI16(n)		(IR_ISI16(EXPRTYPE(n)))
#define RU16(n)		(IR_ISU16(EXPRTYPE(n)))
#define R32(n)		(IR_ISLONG(EXPRTYPE(n)) || IR_ISPTR(EXPRTYPE(n)))
#define RI32(n)		(IR_ISI32(EXPRTYPE(n)))
#define RU32(n)		(IR_ISU32(EXPRTYPE(n)) || IR_ISPTR(EXPRTYPE(n)))
#define R64(n)		(IR_ISQUAD(EXPRTYPE(n)))
#define RI64(n)		(IR_ISI64(EXPRTYPE(n)))
#define RU64(n)		(IR_ISU64(EXPRTYPE(n)))
#define F64(n)		(IR_ISF64(EXPRTYPE(n)))

extern struct regvec div32dst;
extern struct regvec div32l;
extern struct regvec div32r;

static void divregs(struct ir *);
static void divaction(struct cg_ctx *);
static void twoaddr(struct cg_ctx *);
static void intoreg(struct cg_ctx *);
%}

%nonterm insn
%nonterm asg, cb, st
%nonterm int8, int16, int32, int64, flt64
%nonterm dstr8, dstr16, dstr32, dstr64, dstf64
%nonterm r8, r16, r32, r64, f64
%nonterm stk8, stk16, stk32, stk64, stkf64

%%

insn:	asg
	| IR_B emit { "\tjmp\t@T\n" }
	| cb
	| st
	;

asg:	IR_ASG(dstr8, r8) emit { "\tmovl\t@R, @L\n" }
	| IR_ASG(dstr8, int8) emit { "\tmovl\t$@R, @L\n" }
	| IR_ASG(dstr8, stk8) emit { "\tmovzbl\t@RO(@RF), @L\n" }
	| IR_ASG(dstr8, IR_CAST[R8(n)](r8)) emit {
		"\tmovl\t@RL, @L\n"
		"\tandl\t$0xff, @L\n" }
	| IR_ASG(dstr8, IR_CAST[R8(n)](r16)) emit {
		"\tmovl\t@RL, @L\n"
		"\tandl\t$0xff, @L\n" }
	| IR_ASG(dstr8, IR_CAST[R8(n)](r32)) emit {
		"\tmovl\t@RL, @L\n"
		"\tandl\t$0xff, @L\n" }
	| IR_ASG(dstr8, IR_CAST[R8(n)](r64)) emit {
		"\tmovl\t@RLP, @L\n"
		"\tandl\t$0xff, @L\n" }
	| IR_ASG(dstr8, IR_LOAD[R8(n)](r32)) emit { "\tmovzbl\t(@RL), @L\n" }

	| IR_ASG(stk8, r8) emit {
		"\tmovl\t@R, %ecx\n"
		"\tmovb\t%cl, @LO(@LF)\n" }
	| IR_ASG(IR_GVAR[R8(n)], r8) emit {
		"\tmovl\t@R, %ecx\n"
		"\tmovb\t%cl, @L\n" }

	| IR_ASG(dstr16, r16) emit { "\tmovl\t@R, @L\n" }
	| IR_ASG(dstr16, int16) emit { "\tmovl\t$@R, @L\n" }
	| IR_ASG(dstr16, stk16) emit { "\tmovzwl\t@RO(@RF), @L\n" }
	| IR_ASG(dstr16, IR_CAST[RI16(n)](r8[R8(n)])) emit {
		"\tmovl\t@RL, %ecx\n"
		"\tmovsbl\t%cl, @L\n" }
	| IR_ASG(dstr16, IR_CAST[R16(n)](r8[RU8(n)])) emit {
		"\tmovl\t@RL, @L\n"
		"\tandl\t$0xff, @L\n" }
	| IR_ASG(dstr16, IR_CAST[R16(n)](r16)) emit {
		"\tmovl\t@RL, @L\n"
		"\tandl\t$0xffff, @L\n" }
	| IR_ASG(dstr16, IR_CAST[R16(n)](r32)) emit {
		"\tmovl\t@RL, @L\n"
		"\tandl\t$0xffff, @L\n" }
	| IR_ASG(dstr16, IR_CAST[R16(n)](r64)) emit {
		"\tmovl\t@RLP, @L\n"
		"\tandl\t$0xffff, @L\n" }
	| IR_ASG(dstr16, IR_LOAD[R16(n)](r32)) emit { "\tmovzwl\t(@RL), @L\n" }

	| IR_ASG(stk16, r16) emit {
		"\tmovl\t@R, %ecx\n"
		"\tmovw\t%cx, @LO(@LF)\n" }
	| IR_ASG(IR_GVAR[R16(n)], r16) emit {
		"\tmovl\t@L, %ecx\n"
		"\tmovw\t%cx, @L\n" }

	|IR_ASG(dstr32, r32) emit { "\tmovl\t@R, @L\n" }
	| IR_ASG(dstr32, int32) emit { "\tmovl\t$@R, @L\n" }
	| IR_ASG(dstr32, stk32) emit { "\tmovl\t@RO(@RF), @L\n" }
	| IR_ASG(dstr32, IR_GADDR) emit { "\tleal\t@R, @L\n" }
	| IR_ASG(dstr32, IR_LADDR) emit { "\tleal\t@RO(@RF), @L\n" }
	| IR_ASG(dstr32, IR_PADDR) emit { "\tleal\t@RO(@RF), @L\n" }
	| IR_ASG(dstr32, IR_GVAR[R32(n)]) emit { "\tmovl\t@R, @L\n" }

	| IR_ASG(dstr32, IR_CAST[R32(n)](r8[RI8(n)])) emit {
		"\tmovl\t@RL, %ecx\n"
		"\tmovsbl\t%cl, @L\n" }
	| IR_ASG(dstr32, IR_CAST[R32(n)](r8[RU8(n)])) emit {
		"\tmovl\t@RL, @L\n"
		"\tandl\t$0xff, @L\n" }
	| IR_ASG(dstr32, IR_CAST[R32(n)](r16[RI16(n)])) emit {
		"\tmovl\t@RL, %ecx\n"
		"\tmovswl\t%cx, @L\n" }
	| IR_ASG(dstr32, IR_CAST[R32(n)](r16[RU16(n)])) emit {
		"\tmovl\t@RL, @L\n"
		"\tandl\t$0xffff, @L\n" }
	| IR_ASG(dstr32, IR_CAST[R32(n)](r32)) emit { "\tmovl\t@RL, @L\n" }
	| IR_ASG(dstr32, IR_CAST[R32(n)](r64)) emit { "\tmovl\t@RLP, @L\n" }
	| IR_ASG(dstr32, IR_CAST[R32(n)](f64)) emit {
		"\tsubl\t$8, %esp\n"
		"\tfnstcw\t(%esp)\n"
		"\tmovw\t(%esp), %ax\n"
		"\tmovb\t$12, %ah\n"
		"\tmovw\t%ax, 2(%esp)\n"
		"\tfldcw\t2(%esp)\n"
		"\tfistpl\t4(%esp)\n"
		"\tfldcw\t(%esp)\n"
		"\tmovl\t4(%esp), @L\n"
		"\taddl\t$8, %esp\n" }
	| IR_ASG(dstr32, IR_LOAD[R32(n)](r32)) emit { "\tmovl\t(@RL), @L\n" }

	| IR_ASG(dstr32, IR_MUL(r32, r32))
	    action { twoaddr(&nctx) }
	    emit { "\timull\t@RR, @L\n" }
	| IR_ASG(dstr32, IR_DIV(r32, r32))
	    action { divaction(&nctx) }
	    emit { "\tcltd\nidiv\t@RR\n" }
	| IR_ASG(dstr32, IR_MOD(r32, r32)) emit { "#fix!\tmodr32\n" }
	| IR_ASG(dstr32, IR_ADD(r32, r32))
	    action { twoaddr(&nctx) }
	    emit { "\taddl\t@RR, @L\n" }
	| IR_ASG(dstr32, IR_SUB(r32, r32))
	    action { twoaddr(&nctx) }
	    emit { "\tsubl\t@RR, @L\n" }
	| IR_ASG(dstr32, IR_ARS(r32, r32))
	    emit { "\tmovl\t@RR, %ecx\n\tsarl\t%cl, @L\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr32, IR_LRS(r32, r32))
	    emit { "\tmovl\t@RR, %ecx\n\tshrl\t%cl, @L\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr32, IR_LS(r32, r32))
	    emit { "\tmovl\t@RR, %ecx\n\tshll\t%cl, @L\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr32, IR_AND(r32, r32))
	    emit { "\tandl\t@RR, @L\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr32, IR_XOR(r32, r32))
	    emit { "\txorl\t@RR, @L\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr32, IR_OR(r32, r32))
	    emit { "\torl\t@RR, @L\n" }
	    action { twoaddr(&nctx) }

	| IR_ASG(stk32, r32) emit { "\tmovl\t@R, @LO(@LF)\n" }
	| IR_ASG(IR_GVAR[R32(n)], r32) emit { "\tmovl\t@R, @L\n" }

	| IR_ASG(dstr64, r64) emit {
		"\tmovl\t@RP, @LP\n"
		"\tmovl\t@RS, @LS\n" }
	| IR_ASG(dstr64, int64) emit { "#fix!\tr64 = int64\n" }
	| IR_ASG(dstr64, stk64) emit {
		"\tmovl\t@RO(@RF), @LP\n"
		"\tmovl\t(@RO + 4)(@RF), @LS\n" }
	| IR_ASG(dstr64, IR_GVAR[R64(n)]) emit {
		"\tmovl\t@R, @LP\n"
		"\tmovl\t@R+4, @LS\n" }

	| IR_ASG(dstr64, IR_CAST[R64(n)](r8[RI8(n)])) emit {
		"\tmovl\t@RL, @LP\n"
		"\tmovl\t@LP, @LS\n"
		"\tshll\t$24, @LP\n"
		"\tshll\t$24, @LS\n"
		"\tsarl\t$24, @LP\n"
		"\tsarl\t$32, @LS\n" }
	| IR_ASG(dstr64, IR_CAST[R64(n)](r8[RU8(n)])) emit {
		"\tmovl\t@RL, @LP\n"
		"\txorl\t@LS, @LS\n" }
	| IR_ASG(dstr64, IR_CAST[R64(n)](r16[RI16(n)])) emit {
		"\tmovl\t@RL, @LP\n"
		"\tmovl\t@LP, @LS\n"
		"\tshll\t$16, @LP\n"
		"\tshll\t$16, @LS\n"
		"\tsarl\t$16, @LP\n"
		"\tsarl\t$32, @LS\n" }
	| IR_ASG(dstr64, IR_CAST[R64(n)](r16[RU16(n)])) emit {
		"\tmovl\t@RL, @LP\n"
		"\txorl\t@LS, @LS\n" }
	| IR_ASG(dstr64, IR_CAST[R64(n)](r32[RI32(n)])) emit {
		"\tmovl\t@RL, @LP\n"
		"\tmovl\t@RL, @LS\n"
		"\tsarl\t$32, @LS\n" }
	| IR_ASG(dstr64, IR_CAST[R64(n)](r32[RU32(n)])) emit {
		"\tmovl\t@RL, @LP\n"
		"\txorl\t@LS, @LS\n" }

	| IR_ASG(dstr64, IR_LOAD[R64(n)](r32)) emit {
		"\tmovl\t0(@RL), @LP\n"
		"\tmovl\t4(@RL), @LS\n" }

	| IR_ASG(dstr64, IR_MUL(r64, r64))
	    emit { "#fix!\tmulr64\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr64, IR_DIV(r64, r64))
	    emit { "#fix!\tdivr64\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr64, IR_MOD(r64, r64))
	    emit { "#fix!\tmodr64\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr64, IR_ADD(r64, r64))
	    emit { "#fix!\taddr64\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr64, IR_SUB(r64, r64))
	    emit { "#fix!\tsubr64\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr64, IR_ARS(r64, r32))
	    emit { "#fix!\tars r64, r32\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr64, IR_LRS(r64, r32))
	    emit { "#fix!\tlrs r64, r32\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr64, IR_LS(r64, r64))
	    emit { "#fix!\tls rr64 r32\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr64, IR_AND(r64, r64))
	    emit { "#fix!\tand r64, r64\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr64, IR_XOR(r64, r64))
	    emit { "#fix!\txor r64, r64\n" }
	    action { twoaddr(&nctx) }
	| IR_ASG(dstr64, IR_OR(r64, r64))
	    emit { "#fix!\txor r64, r64\n" }
	    action { twoaddr(&nctx) }

	| IR_ASG(stk64, r64) emit {
		"\tmovl\t@RP, @LO(@LF)\n"
		"\tmovl\t@RS, (@LO + 4)(@LF)\n" }

	| IR_ASG(dstf64, f64) emit { "" }
	| IR_ASG(dstf64, flt64) emit { "@ZLD" }
	| IR_ASG(dstf64, stkf64) emit { "\tfldl\t@RO(@RF)\n" }
	| IR_ASG(dstf64, IR_CAST[F64(n)](r32)) emit {
		"\tpushl\t@RL\n"
		"\tfildl\t(%esp)\n"
		"\taddl\t$4, %esp\n" }
	| IR_ASG(dstf64, IR_LOAD[F64(n)](r32)) emit { "\tfldl\t(@RL)\n" }
	| IR_ASG(dstf64, IR_ADD(f64, f64))
	    action { twoaddr(&nctx); }
	    emit { "\tfaddp\t%st(1)\n" }
	| IR_ASG(dstf64, IR_SUB(f64, f64))
	    action { twoaddr(&nctx); }
	    emit { "\tfsubp\t%st(1)\n" }
	| IR_ASG(dstf64, IR_MUL(f64, f64))
	    action { twoaddr(&nctx); }
	    emit { "\tfmulp\t%st(1)\n" }
	| IR_ASG(dstf64, IR_DIV(f64, f64))
	    action { twoaddr(&nctx); }
	    emit { "\tfdivp\t%st(1)\n" }

	| IR_ASG(stkf64, f64) emit { "\tfstpl\t@LO(@LF)\n" }
	;

st:	IR_ST(r32, r8) emit {
		"\tmovl\t@R, %ecx\n"
		"\tmovb\t%cl, (@L)\n" }
	| IR_ST(r32, r16) emit {
		"\tmovl\t@R, %ecx\n"
		"\tmovw\t%cx, (@L)\n" }
	| IR_ST(r32, r32) emit { "\tmovl\t@R, (@L)\n" }
	| IR_ST(r32, r64) emit {
		"\tmovl\t@RP, (@L)\n"
		"\tmovl\t@RS, 4(@L)\n" }
	| IR_ST(r32, f64) emit { "\tfstpl\t(@L)\n" }
	;

cb:	IR_BEQ(r32[RI32(n)], r32[RI32(n)]) emit {
		"\tcmpl\t@R, @L\n"
		"\tje\t@T\n" }
	| IR_BNE(r32[RI32(n)], r32[RI32(n)]) emit {
		"\tcmpl\t@R, @L\n"
		"\tjne\t@T\n" }
	| IR_BLT(r32[RI32(n)], r32[RI32(n)]) emit {
		"\tcmpl\t@R, @L\n"
		"\tjl\t@T\n" }
	| IR_BLE(r32[RI32(n)], r32[RI32(n)]) emit {
		"\tcmpl\t@R, @L\n"
		"\tjle\t@T\n" }
	| IR_BGT(r32[RI32(n)], r32[RI32(n)]) emit {
		"\tcmpl\t@R, @L\n"
		"\tjg\t@T\n" }
	| IR_BGE(r32[RI32(n)], r32[RI32(n)]) emit {
		"\tcmpl\t@R, @L\n"
		"\tjge\t@T\n" }

	| IR_BEQ(r32[RU32(n)], r32[RU32(n)]) emit {
		"\tcmpl\t@R, @L\n"
		"\tje\t@T\n" }
	| IR_BNE(r32[RU32(n)], r32[RU32(n)]) emit {
		"\tcmpl\t@R, @L\n"
		"\tjne\t@T\n" }
	| IR_BLT(r32[RU32(n)], r32[RU32(n)]) emit {
		"\tcmpl\t@R, @L\n"
		"\tjb\t@T\n" }
	| IR_BLE(r32[RU32(n)], r32[RU32(n)]) emit {
		"\tcmpl\t@R, @L\n"
		"\tjbe\t@T\n" }
	| IR_BGT(r32[RU32(n)], r32[RU32(n)]) emit {
		"\tcmpl\t@R, @L\n"
		"\tja\t@T\n" }
	| IR_BGE(r32[RU32(n)], r32[RU32(n)]) emit {
		"\tcmpl\t@R, @L\n"
		"\tjae\t@T\n" }

	| IR_BEQ(r64[RU64(n)], r64[RU64(n)]) emit {
		"#fix!\tbequ64\n" }
	| IR_BNE(r64[RU64(n)], r64[RU64(n)]) emit {
		"#fix!\tbneu64\n" }
	| IR_BLT(r64[RU64(n)], r64[RU64(n)]) emit {
		"#fix!\tbltu64\n" }
	| IR_BLE(r64[RU64(n)], r64[RU64(n)]) emit {
		"#fix!\tbleu64\n" }
	| IR_BGT(r64[RU64(n)], r64[RU64(n)]) emit {
		"#fix!\tbgtu64\n" }
	| IR_BGE(r64[RU64(n)], r64[RU64(n)]) emit {
		"#fix!\tbgeu64\n" }

	| IR_BEQ(f64, f64) emit {
		"\tfucompp\n"
		"\tfnstsw\t%ax\n"
		"\tandb\t$64, %ah\n"
		"\tjne\t@T\n" }
	| IR_BNE(f64, f64) emit {
		"\tfucompp\n"
		"\tfnstsw\t%ax\n"
		"\tandb\t$64, %ah\n"
		"\tje\t@T\n" }
	| IR_BLT(f64, f64) emit {
		"\tfucompp\n"
		"\tfnstsw\t%ax\n"
		"\tandb\t$1, %ah\n"
		"\tjnz\t@T\n" }
	| IR_BLE(f64, f64) emit {
		"\tfucompp\n"
		"\tfnstsw\t%ax\n"
		"\tandb\t$69, %ah\n"
		"\tjne\t@T\n" }
	| IR_BGT(f64, f64) emit {
		"\tfucompp\n"
		"\tfnstsw\t%ax\n"
		"\tandb\t$69, %ah\n"
		"\tje\t@T\n" }
	| IR_BGE(f64, f64) emit {
		"\tfucompp\n"
		"\tfnstsw\t%ax\n"
		"\tandb\t$1, %ah\n"
		"\tjz\t@T\n" }
	;

int8:	IR_ICON[R8(n)]
	;

int16:	IR_ICON[R16(n)]
	;

int32:	IR_ICON[R32(n)]
	;

int64:	IR_ICON[R64(n)]
	;

flt64:	IR_FCON[F64(n)]
	;

dstr8:	IR_REG[R8(n)]
	;

dstr16:	IR_REG[R16(n)]
	;

dstr32:	IR_REG[R32(n)]
	;

dstr64:	IR_REG[R64(n)]
	;

dstf64:	IR_REG[F64(n)]
	;

r8:	IR_REG[R8(n)]
	| IR_GVAR[R8(n)] action { intoreg(&nctx) }
	| stk8 action { intoreg(&nctx) }
	| int8 action { intoreg(&nctx) }
	| IR_CAST[R8(n)](r8) action { intoreg(&nctx) }
	| IR_CAST[R8(n)](r16) action { intoreg(&nctx) }
	| IR_CAST[R8(n)](r32) action { intoreg(&nctx) }
	| IR_CAST[R8(n)](r64) action { intoreg(&nctx) }
	| IR_LOAD[R8(n)](r32) action { intoreg(&nctx) }
	;

r16:	IR_REG[R16(n)]
	| IR_GVAR[R16(n)] action { intoreg(&nctx) }
	| stk16 action { intoreg(&nctx) }
	| int16 action { intoreg(&nctx) }
	| IR_CAST[R16(n)](r8) action { intoreg(&nctx) }
	| IR_CAST[R16(n)](r16) action { intoreg(&nctx) }
	| IR_CAST[R16(n)](r32) action { intoreg(&nctx) }
	| IR_CAST[R16(n)](r64) action { intoreg(&nctx) }
	| IR_LOAD[R16(n)](r32) action { intoreg(&nctx) }
	;

r32:	IR_REG[R32(n)]
	| IR_GADDR action { intoreg(&nctx) }
	| IR_LADDR action { intoreg(&nctx) }
	| IR_PADDR action { intoreg(&nctx) }
	| IR_GVAR[R32(n)] action { intoreg(&nctx) }
	| stk32 action { intoreg(&nctx) }
	| int32 action { intoreg(&nctx) }
	| IR_CAST[R32(n)](r8) action { intoreg(&nctx) }
	| IR_CAST[R32(n)](r16) action { intoreg(&nctx) }
	| IR_CAST[R32(n)](r32) action { intoreg(&nctx) }
	| IR_CAST[R32(n)](r64) action { intoreg(&nctx) }
	| IR_LOAD[R32(n)](r32) action { intoreg(&nctx) }
	| IR_MUL(r32, r32) action { intoreg(&nctx) }
	| IR_DIV(r32, r32) action { intoreg(&nctx) }
	| IR_ADD(r32, r32) action { intoreg(&nctx) }
	| IR_SUB(r32, r32) action { intoreg(&nctx) }
	| IR_ARS(r32, r32) action { intoreg(&nctx) }
	| IR_LRS(r32, r32) action { intoreg(&nctx) }
	| IR_LS(r32, r32) action { intoreg(&nctx) }
	| IR_AND(r32, r32) action { intoreg(&nctx) }
	| IR_XOR(r32, r32) action { intoreg(&nctx) }
	| IR_OR(r32, r32) action { intoreg(&nctx) }
	;

r64:	IR_REG[R64(n)]
	| stk64 action { intoreg(&nctx) }
	| int64 action { intoreg(&nctx) }
	| IR_CAST[R64(n)](r32) action { intoreg(&nctx) }
	| IR_LOAD[R64(n)](r32) action { intoreg(&nctx) }
	| IR_MUL(r64, r64) action { intoreg(&nctx) }
	| IR_DIV(r64, r64) action { intoreg(&nctx) }
	| IR_ADD(r64, r64) action { intoreg(&nctx) }
	| IR_SUB(r64, r64) action { intoreg(&nctx) }
	| IR_ARS(r64, r32) action { intoreg(&nctx) }
	| IR_LRS(r64, r32) action { intoreg(&nctx) }
	| IR_LS(r64, r32) action { intoreg(&nctx) }
	| IR_AND(r64, r64) action { intoreg(&nctx) }
	| IR_XOR(r64, r64) action { intoreg(&nctx) }
	| IR_OR(r64, r64) action { intoreg(&nctx) }
	;

f64:	IR_REG[F64(n)]
	| IR_GVAR[F64(n)] action { intoreg(&nctx) }
	| stkf64 action { intoreg(&nctx) }
	| flt64 action { intoreg(&nctx) }
	| IR_CAST[F64(n)](r32) action { intoreg(&nctx) }
	| IR_LOAD[F64(n)](r32) action { intoreg(&nctx) }
	| IR_ADD(f64, f64) action { intoreg(&nctx) }
	| IR_SUB(f64, f64) action { intoreg(&nctx) }
	| IR_MUL(f64, f64) action { intoreg(&nctx) }
	| IR_DIV(f64, f64) action { intoreg(&nctx) }
	;

stk8:	IR_LVAR[R8(n)]
	| IR_PVAR[R8(n)]
	;

stk16:	IR_LVAR[R16(n)]
	| IR_PVAR[R16(n)]
	;

stk32:	IR_LVAR[R32(n)]
	| IR_PVAR[R32(n)]
	;

stk64:	IR_LVAR[R64(n)]
	| IR_PVAR[R64(n)]
	;

stkf64:	IR_LVAR[F64(n)]
	;

%%

static void
divregs(struct ir *ir)
{
	struct ir_stasg *asg = (struct ir_stasg *)ir;

	asg->is_l->ie_rmask = &div32dst;
	asg->is_r->ie_l->ie_rmask = &div32l;
	asg->is_r->ie_r->ie_rmask = &div32r;
}

static void
divaction(struct cg_ctx *cc)
{
	struct ir_insn *insn;

	twoaddr(cc);
	insn = (struct ir_insn *)cc->cc_insn;
	ir_insn_set_specregs(insn, divregs);
}

static void
twoaddr(struct cg_ctx *cc)
{
	struct ir_expr *reg;
	struct ir_stasg *asg = (struct ir_stasg *)cc->cc_insn;
	struct ir_insn *nasg;
	struct ir_symbol *dst, *l, *r;

	reg = asg->is_l;
	dst = reg->ie_sym;
	l = asg->is_r->ie_l->ie_sym;
	r = asg->is_r->ie_r->ie_sym;

	if (dst == l)
		return;
	if (asg->is_r->i_op == IR_ADD || asg->is_r->i_op == IR_MUL) {
		r = asg->is_r->ie_r->ie_sym;
		if (dst == r) {
			reg = asg->is_r->ie_r;
			asg->is_r->ie_r = asg->is_r->ie_l;
			asg->is_r->ie_l = reg;
			return;
		}
	}

	reg = ir_virtreg(reg->ie_sym);
	nasg = ir_asg(reg, asg->is_r->ie_l);
	reg = ir_virtreg(dst);
	asg->is_r->ie_l = reg;
	ir_prepend_insn((struct ir_insn *)asg, nasg);
	cc->cc_ctx->cc_changes = 1;
}

static void
intoreg(struct cg_ctx *cc)
{
	struct ir_expr *reg, *x;
	struct ir_insn *asg;

	x = (struct ir_expr *)cc->cc_node;
	reg = ir_newvreg(cc->cc_ctx->cc_fn, x->ie_type);
	asg = ir_asg(reg, x);
	ir_prepend_insn((struct ir_insn *)cc->cc_insn, asg);
	reg = ir_virtreg(reg->ie_sym);
	cc->cc_newnode = (struct ir *)reg;
	cc->cc_ctx->cc_changes = 1;
}
